{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from WebTable import findTables, pullTable\n",
    "# from TeamRenamer import Abv2Full, Full2Abv\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from bs4 import Comment\n",
    "from gazpacho import get, Soup\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from time import sleep\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Abv2Full(team_s):\n",
    "    try:\n",
    "        if team_s == 'crd' or team_s == 'ari':\n",
    "            ts = 'Arizona Cardinals'\n",
    "        elif team_s == 'atl':\n",
    "            ts = 'Atlanta Falcons'\n",
    "        elif team_s == 'rav' or team_s == 'bal':\n",
    "            ts = 'Baltimore Ravens'\n",
    "        elif team_s == 'buf':\n",
    "            ts = 'Buffalo Bills'\n",
    "        elif team_s == 'car':\n",
    "            ts = 'Carolina Panthers'\n",
    "        elif team_s == 'chi':\n",
    "            ts = 'Chicago Bears'\n",
    "        elif team_s == 'cin':\n",
    "            ts = 'Cincinnati Bengals'\n",
    "        elif team_s == 'cle':\n",
    "            ts = 'Cleveland Browns'\n",
    "        elif team_s == 'dal':\n",
    "            ts = 'Dallas Cowboys'\n",
    "        elif team_s == 'den':\n",
    "            ts = 'Denver Broncos'\n",
    "        elif team_s == 'det':\n",
    "            ts = 'Detroit Lions'\n",
    "        elif team_s == 'gnb':\n",
    "            ts = 'Green Bay Packers'\n",
    "        elif team_s == 'htx' or team_s == 'hou':\n",
    "            ts = 'Houston Texans'\n",
    "        elif team_s == 'clt' or team_s == 'ind':\n",
    "            ts = 'Indianapolis Colts'\n",
    "        elif team_s == 'jax':\n",
    "            ts = 'Jacksonville Jaguars'\n",
    "        elif team_s == 'kan':\n",
    "            ts = 'Kansas City Chiefs'\n",
    "        elif team_s == 'lac':\n",
    "            ts = 'LA Chargers'\n",
    "        elif team_s == 'lar':\n",
    "            ts = 'LA Rams'\n",
    "        elif team_s == 'mia':\n",
    "            ts = 'Miami Dolphins'\n",
    "        elif team_s == 'min':\n",
    "            ts = 'Minnesota Vikings'\n",
    "        elif team_s == 'nwe':\n",
    "            ts = 'New England Patriots'\n",
    "        elif team_s == 'nor':\n",
    "            ts = 'New Orleans Saints'\n",
    "        elif team_s == 'nyg':\n",
    "            ts = 'New York Giants'\n",
    "        elif team_s == 'nyj':\n",
    "            ts = 'New York Jets'\n",
    "        elif team_s == 'rai' or team_s == 'oak':\n",
    "            ts = 'Oakland Raiders'\n",
    "        elif team_s == 'phi':\n",
    "            ts = 'Philadelphia Eagles'\n",
    "        elif team_s == 'pit':\n",
    "            ts = 'Pittsburgh Steelers'\n",
    "        elif team_s == 'sdg':\n",
    "            ts = 'San Diego Chargers'\n",
    "        elif team_s == 'sfo':\n",
    "            ts = 'San Francisco 49ers'\n",
    "        elif team_s == 'sea':\n",
    "            ts = 'Seattle Seahawks'\n",
    "        elif team_s == 'ram' or team_s == 'stl':\n",
    "            ts = 'St. Louis Rams'\n",
    "        elif team_s == 'tam':\n",
    "            ts = 'Tampa Bay Buccaneers'\n",
    "        elif team_s == 'oti' or team_s == 'ten':\n",
    "            ts = 'Tennessee Titans'\n",
    "        elif team_s == 'was':\n",
    "            ts = 'Washington Redskins'\n",
    "    except NameError:\n",
    "        print('Invalid team name')\n",
    "    return ts\n",
    "\n",
    "def Full2Abv(team_s):\n",
    "    try:\n",
    "        if team_s == 'Arizona Cardinals':\n",
    "            ts = 'crd'\n",
    "        elif team_s == 'Atlanta Falcons':\n",
    "            ts = 'atl'\n",
    "        elif team_s == 'Baltimore Ravens':\n",
    "            ts = 'rav'\n",
    "        elif team_s == 'Buffalo Bills':\n",
    "            ts = 'buf'\n",
    "        elif team_s == 'Carolina Panthers':\n",
    "            ts = 'car'\n",
    "        elif team_s == 'Chicago Bears':\n",
    "            ts = 'chi'\n",
    "        elif team_s == 'Cincinnati Bengals':\n",
    "            ts = 'cin'\n",
    "        elif team_s == 'Cleveland Browns':\n",
    "            ts = 'cle'\n",
    "        elif team_s == 'Dallas Cowboys':\n",
    "            ts = 'dal'\n",
    "        elif team_s == 'Denver Broncos':\n",
    "            ts = 'den'\n",
    "        elif team_s == 'Detroit Lions':\n",
    "            ts = 'det'\n",
    "        elif team_s == 'Green Bay Packers':\n",
    "            ts = 'gnb'\n",
    "        elif team_s == 'Houston Texans':\n",
    "            ts = 'htx'\n",
    "        elif team_s == 'Indianapolis Colts':\n",
    "            ts = 'clt'\n",
    "        elif team_s == 'Jacksonville Jaguars':\n",
    "            ts = 'jax'\n",
    "        elif team_s == 'Kansas City Chiefs':\n",
    "            ts = 'kan'\n",
    "        elif team_s == 'Miami Dolphins':\n",
    "            ts = 'mia'\n",
    "        elif team_s == 'Minnesota Vikings':\n",
    "            ts = 'min'\n",
    "        elif team_s == 'New England Patriots':\n",
    "            ts = 'nwe'\n",
    "        elif team_s == 'New Orleans Saints':\n",
    "            ts = 'nor'\n",
    "        elif team_s == 'New York Giants':\n",
    "            ts = 'nyg'\n",
    "        elif team_s == 'New York Jets':\n",
    "            ts = 'nyj'\n",
    "        elif team_s == 'Oakland Raiders':\n",
    "            ts = 'rai'\n",
    "        elif team_s == 'Philadelphia Eagles':\n",
    "            ts = 'phi'\n",
    "        elif team_s == 'Pittsburgh Steelers':\n",
    "            ts = 'pit'\n",
    "        elif team_s == 'San Diego Chargers':\n",
    "            ts = 'sdg'\n",
    "        elif team_s == 'San Francisco 49ers':\n",
    "            ts = 'sfo'\n",
    "        elif team_s == 'Seattle Seahawks':\n",
    "            ts = 'sea'\n",
    "        elif team_s == 'St. Louis Rams':\n",
    "            ts = 'ram'\n",
    "        elif team_s == 'Tampa Bay Buccaneers':\n",
    "            ts = 'tam'\n",
    "        elif team_s == 'Tennessee Titans':\n",
    "            ts = 'oti'\n",
    "        elif team_s == 'Washington Redskins':\n",
    "            ts = 'was'\n",
    "    except NameError:\n",
    "        print('Invalid team name')\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abv2Full('stl')\n",
    "# Full2Abv('Arizona Cardinals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_list = ['crd', 'atl', 'rav', 'buf', 'car', 'chi', 'cin', 'cle', 'dal', 'den', 'det','gnb', \n",
    "'htx', 'clt', 'jax', 'kan', 'mia', 'min', 'nwe', 'nor', 'nyg', 'nyj', 'rai', 'phi', 'pit', \n",
    "'sdg', 'sfo', 'sea', 'ram', 'tam', 'oti', 'was']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urlSplit(inputlist):\n",
    "    ''' Used to slice the boxscore link to get and sort link and date\n",
    "    '''\n",
    "    urlList = []\n",
    "    for item in inputlist:\n",
    "        sort = item.split('/')[-1][:9]\n",
    "        urlList.append(sort)\n",
    "    return sorted(urlList, reverse=False)\n",
    "\n",
    "def Nanreplace(x):\n",
    "    if pd.isnull(x['relative_humidity']):\n",
    "        return x['relative humidity']\n",
    "    else:\n",
    "        return x['relative_humidity']\n",
    "\n",
    "def boxscore(url):\n",
    "    '''returns the link to the boxscore and the date the game was played'''\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    boxlinks = str(soup.find('a', {'href': 'boxscore'})).split('\"')                    # Finds all a tags with a href link and splits on \"\n",
    "    links_list = [x for x in boxlinks if x.startswith('/boxscore')][1:-3]              # creates a list of all the links that starts with /boxscore\n",
    "    links_list = ['https://www.pro-football-reference.com' + x for x in links_list]    # creates the complete url to the boxscore links\n",
    "    df = pd.DataFrame(links_list, columns =['Links'])                                  # creates a dataframe containing all of the url links just created\n",
    "    df['Date'] = urlSplit(links_list)                                                  # add a new column that uses urlSplit to get an idea of the date\n",
    "    return df\n",
    "\n",
    "def get_boxscore_stats(url):\n",
    "    '''reutns a dataframe that contains home and away boxscores\n",
    "    use the link from the boxscore link generated from the master\n",
    "    dataframe\n",
    "    '''\n",
    "    boxstats = pullTable(url,'team_stats')                                             # Pull box table from boxscore url\n",
    "    boxstats.columns = ['Stats', 'Away', 'Home']                                       # rename column names\n",
    "    homebox = boxstats[['Stats','Home']]                                               # create a list for home and away teams\n",
    "    awaybox = boxstats[['Stats','Away']]\n",
    "    homebox = homebox.transpose()                                                      # Transpose the tables\n",
    "    awaybox = awaybox.transpose()\n",
    "    home_colnames = ['Home_' + x for x in homebox.iloc[0]]                             # add Home or Away to column names\n",
    "    away_colnames = ['Away_' + x for x in awaybox.iloc[0]]\n",
    "    zip_Homeboxscore = list(zip(home_colnames, homebox.iloc[1]))                       # zip list of columns and data together\n",
    "    zip_Awayboxscore = list(zip(away_colnames, awaybox.iloc[1]))\n",
    "    boxscorelist = zip_Homeboxscore + zip_Awayboxscore                                 # combine lists together\n",
    "    box_col = [col[0].replace(' ','_').replace('.','') for col in boxscorelist]        # Replace spaces with _ and remove .\n",
    "    box_stats = pd.Series([col[1] for col in boxscorelist], index=box_col)             \n",
    "    boxdf= pd.DataFrame(columns=box_col)\n",
    "    boxdf = boxdf.append(box_stats, ignore_index=True)\n",
    "    #Split multiple data from one columns into individual columns\n",
    "    statSplit = [x.split('-') for x in boxdf['Home_Rush-Yds-TDs']]\n",
    "    boxdf['Home_Rush_Att'] = statSplit[0][0]\n",
    "    boxdf['Home_Rush_Yds'] = statSplit[0][1]\n",
    "    boxdf['Home_Rush_TDs'] = statSplit[0][2]\n",
    "    statSplit = [x.split('-') for x in boxdf['Away_Rush-Yds-TDs']]\n",
    "    boxdf['Away_Rush_Att'] = statSplit[0][0]\n",
    "    boxdf['Away_Rush_Yds'] = statSplit[0][1]\n",
    "    boxdf['Away_Rush_TDs'] = statSplit[0][2]\n",
    "    statSplit = [x.split('-') for x in boxdf['Home_Cmp-Att-Yd-TD-INT']]\n",
    "    boxdf['Home_Pass_Comp'] = statSplit[0][0]\n",
    "    boxdf['Home_Pass_Att'] = statSplit[0][1]\n",
    "    boxdf['Home_Pass_Yd'] = statSplit[0][2]\n",
    "    boxdf['Home_Pass_TD'] = statSplit[0][3]\n",
    "    boxdf['Home_Pass_INT'] = statSplit[0][4]\n",
    "    statSplit = [x.split('-') for x in boxdf['Away_Cmp-Att-Yd-TD-INT']]\n",
    "    boxdf['Away_Pass_Comp'] = statSplit[0][0]\n",
    "    boxdf['Away_Pass_Att'] = statSplit[0][1]\n",
    "    boxdf['Away_Pass_Yd'] = statSplit[0][2]\n",
    "    boxdf['Away_Pass_TD'] = statSplit[0][3]\n",
    "    boxdf['Away_Pass_INT'] = statSplit[0][4]\n",
    "    statSplit = [x.split('-') for x in boxdf['Home_Penalties-Yards']]\n",
    "    boxdf['Home_Penalties'] = statSplit[0][0]\n",
    "    boxdf['Home_Penalties_Yd'] = statSplit[0][1]\n",
    "    statSplit = [x.split('-') for x in boxdf['Away_Penalties-Yards']]\n",
    "    boxdf['Away_Penalties'] = statSplit[0][0]\n",
    "    boxdf['Away_Penalties_Yd'] = statSplit[0][1]\n",
    "    statSplit = [x.split('-') for x in boxdf['Home_Sacked-Yards']]\n",
    "    boxdf['Home_Sacks'] = statSplit[0][0]\n",
    "    boxdf['Home_SackedYards'] = statSplit[0][1]\n",
    "    statSplit = [x.split('-') for x in boxdf['Away_Sacked-Yards']]\n",
    "    boxdf['Home_Sacks'] = statSplit[0][0]\n",
    "    boxdf['Home_SackedYards'] = statSplit[0][1]\n",
    "    statSplit = [x.split('-') for x in boxdf['Home_Fumbles-Lost']]\n",
    "    boxdf['Home_Fumbles'] = statSplit[0][0]\n",
    "    boxdf['Home_Fumbles_Losts'] = statSplit[0][1]\n",
    "    statSplit = [x.split('-') for x in boxdf['Away_Fumbles-Lost']]\n",
    "    boxdf['Away_Fumbles'] = statSplit[0][0]\n",
    "    boxdf['Away_Fumbles_Losts'] = statSplit[0][1]\n",
    "    #Conversion to precentages \n",
    "    statSplit = [x.split('-') for x in boxdf['Home_Third_Down_Conv']]\n",
    "    if int(statSplit[0][1]) != 0: \n",
    "        boxdf['Home_Third_Down_Conv'] = int(statSplit[0][0])/int(statSplit[0][1]) * 100\n",
    "    else: \n",
    "        boxdf['Home_Third_Down_Conv'] = 0\n",
    "    statSplit = [x.split('-') for x in boxdf['Away_Third_Down_Conv']]\n",
    "    if int(statSplit[0][1]) != 0:\n",
    "        boxdf['Away_Third_Down_Conv'] = int(statSplit[0][0])/int(statSplit[0][1]) * 100\n",
    "    else: \n",
    "        boxdf['Away_Third_Down_Conv'] = 0\n",
    "    statSplit = [x.split('-') for x in boxdf['Home_Fourth_Down_Conv']]\n",
    "    if int(statSplit[0][1]) != 0:\n",
    "        boxdf['Home_Fourth_Down_Conv'] = int(statSplit[0][0])/int(statSplit[0][1]) * 100\n",
    "    else:\n",
    "        boxdf['Home_Fourth_Down_Conv'] = 0 \n",
    "    statSplit = [x.split('-') for x in boxdf['Away_Fourth_Down_Conv']]\n",
    "    if int(statSplit[0][1]) != 0:  \n",
    "        boxdf['Away_Fourth_Down_Conv'] = int(statSplit[0][0])/int(statSplit[0][1]) * 100\n",
    "    else:\n",
    "        boxdf['Away_Fourth_Down_Conv'] = 0\n",
    "    boxdf.drop(['Home_Rush-Yds-TDs','Away_Rush-Yds-TDs','Home_Cmp-Att-Yd-TD-INT','Away_Cmp-Att-Yd-TD-INT',\n",
    "               'Home_Penalties-Yards','Away_Penalties-Yards','Home_Sacked-Yards','Away_Sacked-Yards',\n",
    "               'Home_Fumbles-Lost','Away_Fumbles-Lost'], axis=1, inplace=True)\n",
    "    boxdf['GetBoxScoreURL'] = url\n",
    "    return boxdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getGameInfo(url):\n",
    "    '''Gets table from Game Info table that is within a HTML comment\n",
    "    Will return a list of lists were [n][0] = column name and [n][1] is the infomation\n",
    "    [('Won_Toss', 'Cardinals (deferred)'),\n",
    "     ('Roof', 'retractable roof (closed)'),\n",
    "     ('Surface', 'grass'),\n",
    "     ('Duration', '2:56'),\n",
    "     ('Attendance', ' 60,104 '),\n",
    "     ('Vegas Line', 'Arizona Cardinals -2.5'),\n",
    "     ('Over/Under', '46.0(over) ')\n",
    "    '''\n",
    "    html = get(url)\n",
    "    soup = BS(html, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))                        # retrieve all the comments from the HTML\n",
    "    game_comments = []\n",
    "\n",
    "    for line in comments:\n",
    "        if '<div class=\"table_outer_container\">' in line:                                          # loop throught the table i want\n",
    "            game_comments.append(re.sub('<[^>]+>', ' ', line))                                     # use regex to replace everything between the <> tags and append to game comments\n",
    "            if '</table>' in line:                                                                 # break out of the for loop once it hits the ending table tag \n",
    "                break\n",
    "    game_info = [x.split('\\n') for x in game_comments]                                             # split on newlines to create a clean list\n",
    "    game_info = game_info[0][5:13]                                                                 # more cleaning, i only want these 8 items\n",
    "    game_info = [x.replace('Won Toss','Won_Toss') if 'Won Toss' in x else x for x in game_info]    # replace the space in the Won Toss item, cleaning/prep\n",
    "    game_info                                                                               \n",
    "    for count, row in enumerate(game_info):\n",
    "        if count == 5 and 'Weather' in row:                                                        \n",
    "            game_info.pop(count)\n",
    "    clean_info = []\n",
    "    for x in game_info:\n",
    "        if x[:2] == '  ':\n",
    "            if x[-2:] == '  ':\n",
    "                clean_info.append(x[2:-2])\n",
    "            else:\n",
    "                clean_info.append(x[2:])\n",
    "        else:\n",
    "            clean_info.append(x)\n",
    "    clean_info = [x.replace('  (','(').replace(' (','(').replace('   ','  ').replace(') ',')') for x in clean_info]\n",
    "    clean_info = [x for x in clean_info if x]\n",
    "    game = [x.split('  ') for x in clean_info]\n",
    "    game_titles = [x[0] for x in game]\n",
    "    game_data = [x[1] for x in game]\n",
    "    #split on | and setting max split to 2 and then removing the empty list items \n",
    "    game = pd.DataFrame([game_data], columns = game_titles)\n",
    "    game['VegasLink'] = url\n",
    "    return game\n",
    "\n",
    "def getQBStats(url):\n",
    "    '''Gets Advanced Passing table from the boxscore page.\n",
    "    The website only has this table in 2018 and 2019'''\n",
    "    qb = pullTable(url, 'passing_advanced')\n",
    "    home_col = ['HOME_QB_' + x.replace('/','-') for x in qb.columns]\n",
    "    away_col = ['AWAY_QB_' + x.replace('/','-') for x in qb.columns]\n",
    "    qb_cols = home_col + away_col\n",
    "    awayqb = [x for x in qb.iloc[0]]\n",
    "    homeqb = [x for x in qb.iloc[1]]\n",
    "    qblist = homeqb + awayqb\n",
    "    qbdf = pd.DataFrame([qblist], columns=qb_cols)\n",
    "    qbdf['HOME_QB_Tm'][0],qbdf['AWAY_QB_Tm'][0] = qbdf['HOME_QB_Tm'][0].lower(),qbdf['AWAY_QB_Tm'][0].lower()\n",
    "    qbdf['QBLINK'] = url\n",
    "    return qbdf\n",
    "\n",
    "def PlayerStats(url):\n",
    "    '''Will return a single row dataframe with QB, RB1, RB2, WR1, WR2, WR3\n",
    "    Stats from the provided url. URL must be the boxscore link from the \n",
    "    GetMaster Function'''\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    dfstats = pd.read_html(str(soup.find('table')[2]))[0]\n",
    "    #flatten multi Index header\n",
    "    columns = [row[0] + '_' + row[1] for row in dfstats.columns]\n",
    "    columns = [x.replace('Unnamed: 0_level_0_Player', 'Player').replace('Unnamed: 1_level_0_Tm','Team') for x in columns]\n",
    "    # droping 'Fumble columns'\n",
    "    columns = [i for i in columns if 'Fumble' not in i]\n",
    "    home_columns = ['Home_QB_' + x for x in columns]\n",
    "    away_columns = ['Away_QB_' + x for x in columns]\n",
    "    if len(dfstats.columns) == 22:\n",
    "        dfstats.drop(('Fumbles', 'Fmb'), axis = 1, inplace = True)\n",
    "        dfstats.drop(('Fumbles', 'FL'), axis = 1, inplace = True)\n",
    "    dfstats.columns = columns\n",
    "    home_qb = []\n",
    "    away_qb = []\n",
    "    qb_cols = away_columns + home_columns\n",
    "    Home_staters = pullTable(url,'home_starters')\n",
    "    Away_staters = pullTable(url,'vis_starters')\n",
    "    Home_staters = Home_staters[:11]\n",
    "    Away_staters = Away_staters[:11]\n",
    "    Starters = pd.concat([Home_staters,Away_staters])\n",
    "    # Joining tables and cleaning table\n",
    "    positions = dfstats.join(Starters.set_index('Player'), on='Player')\n",
    "    away_team = positions['Team'].iloc[0]\n",
    "    home_team = positions['Team'].iloc[-1]\n",
    "    alinks = str(soup.find('table',{'id':\"player_offense\"}))\n",
    "    basenamelink = 'https://www.pro-football-reference.com/'\n",
    "    namelink = alinks.split('href')\n",
    "    namelink = namelink[1:]\n",
    "    namelink = [x.split('\"')[1] for x in namelink]\n",
    "    PosName = []\n",
    "    Play_Name= []\n",
    "    for x in namelink:\n",
    "        getname = basenamelink + x\n",
    "        html_name = get(getname)\n",
    "        soup_name = Soup(html_name)\n",
    "        playerposition = str(soup_name.find('div',{'id':\"meta\"}))\n",
    "        playerposition = playerposition.split('Position')\n",
    "        Pos_Name = playerposition[1][11:13]\n",
    "        PlayerName = re.sub('<[^>]+>', ' ',playerposition[0]).strip()\n",
    "        PlayerName = [' '.join(PlayerName.split(' ')[:2])]\n",
    "        Play_Name.extend(PlayerName)\n",
    "        PosName.append(Pos_Name)\n",
    "\n",
    "    NamePosDict = {Play_Name[i] : PosName[i] for i in range(len(Play_Name))}\n",
    "    positions['Pos']=positions['Player'].apply(lambda x: NamePosDict.get(x,x))\n",
    "    away_qb = []\n",
    "    home_qb = []\n",
    "    for index, row in positions.iterrows():\n",
    "        if row['Pos'] == 'QB':\n",
    "            if row['Team'] == home_team:\n",
    "                home_qb.extend(row)\n",
    "            else:\n",
    "                away_qb.extend(row)\n",
    "    qb = home_qb + away_qb\n",
    "    qb_filler = ['Bobby Boucher','SCLSU','9999','9999','9999','9999','9999','9999','9999','9999','9999',\n",
    "                 '9999','9999','9999','9999','9999','9999','9999','9999','9999']\n",
    "    away_qb = away_qb[:21]\n",
    "    home_qb = home_qb[:21]\n",
    "    if away_qb == []:\n",
    "        away_qb = qb_filler\n",
    "    if home_qb == []:\n",
    "        home_qb = qb_filler\n",
    "    qb = home_qb + away_qb\n",
    "    qb = [x for x in qb if x!= 'QB']\n",
    "    qb_col = home_columns + away_columns\n",
    "    QB = pd.DataFrame([qb], columns=qb_col)\n",
    "    QB = QB.drop(QB.filter(regex='Receiving').columns, axis=1)\n",
    "\n",
    "    #Start Cleaning up the postions dataframe and then create RB, WR, TE DataFrames then add them all together to return\n",
    "    position_drop = ['Passing_Cmp','Passing_Att','Passing_Yds','Passing_TD', 'Passing_Int', 'Passing_Sk',\n",
    "                    'Passing_Yds.1','Passing_Lng', 'Passing_Rate']\n",
    "    positions.drop(position_drop, axis = 1, inplace=True)\n",
    "    positions = positions[positions.Pos != 'QB']\n",
    "    positions = positions[positions.Team.notna()]\n",
    "    pos_col = positions.columns\n",
    "    # positions = positions[(positions.Pos != 'QB')|(positions.Pos.notna())]\n",
    "    positions = positions[(positions.Pos != 'QB')]\n",
    "\n",
    "    home_wr = []\n",
    "    away_wr = []\n",
    "    home_rb = []\n",
    "    away_rb = []\n",
    "    for index, row in positions.iterrows():\n",
    "        if row['Pos'] == 'RB' or row['Pos'] == 'FB':\n",
    "            if row['Team'] == home_team:\n",
    "                home_rb.append(row.values)\n",
    "            else:\n",
    "                away_rb.append(row.values)\n",
    "        elif row['Pos'] == 'WR' or row['Pos'] == 'TE':\n",
    "            if row['Team'] == home_team:\n",
    "                home_wr.append(row.values)\n",
    "            else:\n",
    "                away_wr.append(row.values)\n",
    "    #Creating Home and Away DataFrames to split each row out from\n",
    "    HOMEWRtemp,AWAYWRtemp = pd.DataFrame(home_wr, columns=pos_col),pd.DataFrame(away_wr, columns=pos_col)\n",
    "    HOMERBtemp,AWAYRBtemp = pd.DataFrame(home_rb, columns=pos_col),pd.DataFrame(away_rb, columns=pos_col)\n",
    "    #creating column names for each position WR1-3 and RB-1\n",
    "    hrb1_col, hrb2_col, arb1_col, arb2_col = ['H_RB1_'+ x for x in pos_col],['H_RB2_'+ x for x in pos_col],['A_RB1_'+ x for x in pos_col],['A_RB2_'+ x for x in pos_col]\n",
    "    hwr1_col, hwr2_col, hwr3_col = ['H_WR1_'+ x for x in pos_col],['H_WR2_'+ x for x in pos_col],['H_WR3_'+ x for x in pos_col]\n",
    "    awr1_col, awr2_col, awr3_col = ['A_WR1_'+ x for x in pos_col],['A_WR2_'+ x for x in pos_col],['A_WR3_'+ x for x in pos_col]\n",
    "    #creating a datafram for each play that will be combined into one row later\n",
    "    hrb_col,arb_col = hrb1_col+hrb2_col,arb1_col+arb2_col\n",
    "    hwr_col,awr_col = hwr1_col+hwr2_col+hwr3_col, awr1_col+awr2_col+awr3_col\n",
    "    \n",
    "    Filler_Rec = ['Forrest Gump', 'Ala', '999', '999', '999', '999', '999', '999', '999', '999',\n",
    "       '-1', 'XX']\n",
    "    if HOMERBtemp.shape[0]==1:\n",
    "        HRBlist = list(HOMERBtemp.iloc[0].values) + Filler_Rec\n",
    "    else:\n",
    "        HRBlist = list(HOMERBtemp.iloc[0].values) + list(HOMERBtemp.iloc[1].values)\n",
    "\n",
    "    if AWAYRBtemp.shape[0]==1:\n",
    "        ARBlist = list(AWAYRBtemp.iloc[0].values) + Filler_Rec\n",
    "    else:\n",
    "        ARBlist = list(AWAYRBtemp.iloc[0].values) + list(AWAYRBtemp.iloc[1].values)\n",
    "\n",
    "    if HOMEWRtemp.shape[0]==1:\n",
    "        HWRlist = list(HOMEWRtemp.iloc[0].values) + Filler_Rec + Filler_Rec\n",
    "    elif HOMEWRtemp.shape[0]==2:\n",
    "        HWRlist = list(HOMEWRtemp.iloc[0].values) + list(HOMEWRtemp.iloc[1].values) + Filler_Rec\n",
    "    else:\n",
    "        HWRlist = list(HOMEWRtemp.iloc[0].values) + list(HOMEWRtemp.iloc[1].values) + list(HOMEWRtemp.iloc[2].values) \n",
    "\n",
    "    if AWAYWRtemp.shape[0]==1:\n",
    "        AWRlist = list(AWAYWRtemp.iloc[0].values) + list(Filler_Rec) + list(Filler_Rec)\n",
    "    elif AWAYWRtemp.shape[0]==2:\n",
    "        AWRlist = list(AWAYWRtemp.iloc[0].values) + list(AWAYWRtemp.iloc[1].values) + list(Filler_Rec)\n",
    "    else:\n",
    "        AWRlist = list(AWAYWRtemp.iloc[0].values) + list(AWAYWRtemp.iloc[1].values) + list(AWAYWRtemp.iloc[2].values) \n",
    "\n",
    "    #Create Home and away Dataframes\n",
    "    HRB, ARB = pd.DataFrame([HRBlist], columns=hrb_col),pd.DataFrame([ARBlist], columns=arb_col)\n",
    "    HWR, AWR = pd.DataFrame([HWRlist], columns=hwr_col),pd.DataFrame([AWRlist], columns=awr_col)\n",
    "    #Concat players stats into one row dataframe\n",
    "    Player_stats = pd.concat([QB,HRB,ARB,HWR,AWR], join='outer', axis=1)\n",
    "    Player_stats['PlayersURL'] = url \n",
    "    return Player_stats\n",
    "\n",
    "\n",
    "def get_master_df(teamList, startyear, endyear):\n",
    "    endyear = endyear + 1\n",
    "#     years = [x for x in range(startyear,endyear)]\n",
    "    masterdf = pd.DataFrame()\n",
    "    for x in tnrange(startyear,endyear, desc='YEAR'):\n",
    "        nflDF = pd.DataFrame()\n",
    "        for team in tqdm_notebook((team_list), desc='TEAMS'):\n",
    "            try:\n",
    "                year = x\n",
    "                base = 'https://www.pro-football-reference.com'\n",
    "                url = base + '/teams/' + team + '/' + str(year) + '.htm'\n",
    "                html = get(url)\n",
    "                soup = Soup(html)\n",
    "                df = pd.read_html(str(soup.find('table')[1]))[0]\n",
    "                df = df[df['Unnamed: 9_level_0','Opp'] != 'Bye Week']\n",
    "                df = df[df['Unnamed: 9_level_0','Opp'] != 'Playoffs']\n",
    "                df['Team','Name'] = Abv2Full(team)\n",
    "                df['Team','Year'] = year\n",
    "                top_level = df.columns.get_level_values(0).astype(str)\n",
    "                lower_level = df.columns.get_level_values(1).astype(str)\n",
    "                df.columns = top_level + '_' + lower_level\n",
    "                df.columns = [x.replace(\"', '\",\"_\").replace('Offense','Home').replace('Defense','Away') for x in df.columns]\n",
    "                df.rename(columns = {'Unnamed: 0_level_0_Week':'Week','Unnamed: 1_level_0_Day':'Day','Unnamed: 2_level_0_Date':'Date',\n",
    "                                          'Unnamed: 3_level_0_Unnamed: 3_level_1':'Time_ET','Unnamed: 4_level_0_Unnamed: 4_level_1':'BOXSCORE',\n",
    "                                          'Unnamed: 5_level_0_Unnamed: 5_level_1':'W_L','Unnamed: 6_level_0_OT':'OT','Unnamed: 7_level_0_Rec':'Home_Record',\n",
    "                                          'Unnamed: 8_level_0_Unnamed: 8_level_1':'HomeOrAway','Unnamed: 9_level_0_Opp':'Opp','Score_Tm':'Home_Score',\n",
    "                                          'Score_Opp':'Away_Score'},inplace=True)\n",
    "                df.drop(['Home_1stD','Home_PassY','Home_RushY','Home_TO','Away_1stD','Away_PassY','Away_TO'], axis=1, inplace=True)\n",
    "                df = df.reset_index(drop=True)\n",
    "                boxscorelink = boxscore(url)\n",
    "                mergedf =  df.merge(boxscorelink, left_index=True, right_index=True)\n",
    "                gameinfo =  pd.DataFrame()\n",
    "                for index, row in mergedf.iterrows():\n",
    "                    try:\n",
    "        #                 Advance Passing stats one good in 2018 and 2019\n",
    "        #                 qb = getQBStats(row['Links'])\n",
    "                        qbStats = PlayerStats(row['Links'])\n",
    "                        boxScoreStats = get_boxscore_stats(row['Links'])\n",
    "                        vegas = getGameInfo(row['Links'])\n",
    "        #                 row_info = pd.concat([qb, stats], axis=1, join='inner')\n",
    "        #                 vegas_stats = pd.concat([row_info, vegas], axis=1, join='inner')\n",
    "        #                 vegas_stats = stats.join(vegas.set_index('VegasLink'), on='GetBoxScoreURL')\n",
    "                        gamerow = pd.concat([qbStats,boxScoreStats,vegas], join='outer',axis=1)\n",
    "                        gameinfo = gameinfo.append(gamerow, ignore_index=True, sort=False)\n",
    "                    except:\n",
    "                        pass\n",
    "                gameinfo = pd.merge(mergedf, gameinfo, left_on='Links', right_on='GetBoxScoreURL')\n",
    "                if 'Date_x' in gameinfo.columns:\n",
    "                    gameinfo.rename(columns = {'Date_x':'Date'}, inplace=True)\n",
    "                nflDF = nflDF.append(gameinfo,ignore_index=True, sort = False)\n",
    "            except:\n",
    "                pass\n",
    "        masterdf = masterdf.append(nflDF,ignore_index=True, sort = False)\n",
    "        sleep(1)\n",
    "    return masterdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master = get_master_df(team_list,2010,2020)\n",
    "master.to_csv(r'./data/MASTER2010_2020.csv', encoding='utf-8', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = get_master_df(team_list,2002,2010)\n",
    "master.to_csv(r'./data/MASTER2002_2010.csv', encoding='utf-8', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master02_10 = pd.read_csv('./data/MASTER2002_2010.csv',index_col='Unnamed: 0')\n",
    "master10_20 = pd.read_csv('./data/MASTER2010_2020.csv',index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.concat([master02_10,master10_20])\n",
    "master['HomeOrAway'] = master['HomeOrAway'].astype(str)\n",
    "master = master[~master.HomeOrAway.str.contains('@')]\n",
    "master.drop(['PlayersURL','VegasLink','GetBoxScoreURL','Weather','BOXSCORE', 'HomeOrAway','Links'], axis=1, inplace=True)\n",
    "master = master.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "master.to_csv(r'./data/MASTERFULL.csv', encoding='utf-8', header='true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
