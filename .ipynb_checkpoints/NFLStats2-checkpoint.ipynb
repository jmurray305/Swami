{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from WebTable import findTables, pullTable\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from bs4 import Comment\n",
    "from gazpacho import get, Soup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['team_stats',\n",
       " 'games',\n",
       " 'team_conversions',\n",
       " 'passing',\n",
       " 'rushing_and_receiving',\n",
       " 'returns',\n",
       " 'kicking',\n",
       " 'defense',\n",
       " 'scoring',\n",
       " 'team_td_log',\n",
       " 'opp_td_log']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findTables('https://www.pro-football-reference.com/teams/tam/2018.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rename_Abv2Full(team_s):\n",
    "    try:\n",
    "        if team_s == 'crd' :\n",
    "            ts = 'Arizona Cardinals'\n",
    "        elif team_s == 'atl':\n",
    "            ts = 'Atlanta Falcons'\n",
    "        elif team_s == 'rav':\n",
    "            ts = 'Baltimore Ravens'\n",
    "        elif team_s == 'buf':\n",
    "            ts = 'Buffalo Bills'\n",
    "        elif team_s == 'car':\n",
    "            ts = 'Carolina Panthers'\n",
    "        elif team_s == 'chi':\n",
    "            ts = 'Chicago Bears'\n",
    "        elif team_s == 'cin':\n",
    "            ts = 'Cincinnati Bengals'\n",
    "        elif team_s == 'cle':\n",
    "            ts = 'Cleveland Browns'\n",
    "        elif team_s == 'dal':\n",
    "            ts = 'Dallas Cowboys'\n",
    "        elif team_s == 'den':\n",
    "            ts = 'Denver Broncos'\n",
    "        elif team_s == 'det':\n",
    "            ts = 'Detroit Lions'\n",
    "        elif team_s == 'gnb':\n",
    "            ts = 'Green Bay Packers'\n",
    "        elif team_s == 'htx':\n",
    "            ts = 'Houston Texans'\n",
    "        elif team_s == 'clt':\n",
    "            ts = 'Indianapolis Colts'\n",
    "        elif team_s == 'jax':\n",
    "            ts = 'Jacksonville Jaguars'\n",
    "        elif team_s == 'kan':\n",
    "            ts = 'Kansas City Chiefs'\n",
    "        elif team_s == 'mia':\n",
    "            ts = 'Miami Dolphins'\n",
    "        elif team_s == 'min':\n",
    "            ts = 'Minnesota Vikings'\n",
    "        elif team_s == 'nwe':\n",
    "            ts = 'New England Patriots'\n",
    "        elif team_s == 'nor':\n",
    "            ts = 'New Orleans Saints'\n",
    "        elif team_s == 'nyg':\n",
    "            ts = 'New York Giants'\n",
    "        elif team_s == 'nyj':\n",
    "            ts = 'New York Jets'\n",
    "        elif team_s == 'rai':\n",
    "            ts = 'Oakland Raiders'\n",
    "        elif team_s == 'phi':\n",
    "            ts = 'Philadelphia Eagles'\n",
    "        elif team_s == 'pit':\n",
    "            ts = 'Pittsburgh Steelers'\n",
    "        elif team_s == 'sdg':\n",
    "            ts = 'San Diego Chargers'\n",
    "        elif team_s == 'sfo':\n",
    "            ts = 'San Francisco 49ers'\n",
    "        elif team_s == 'sea':\n",
    "            ts = 'Seattle Seahawks'\n",
    "        elif team_s == 'ram':\n",
    "            ts = 'St. Louis Rams'\n",
    "        elif team_s == 'tam':\n",
    "            ts = 'Tampa Bay Buccaneers'\n",
    "        elif team_s == 'oti':\n",
    "            ts = 'Tennessee Titans'\n",
    "        elif team_s == 'was':\n",
    "            ts = 'Washington Redskins'\n",
    "    except NameError:\n",
    "        print('Invalid team name')\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameFull2Abv(team_s):\n",
    "    try:\n",
    "        if team_s == 'Arizona Cardinals':\n",
    "            ts = 'crd'\n",
    "        elif team_s == 'Atlanta Falcons':\n",
    "            ts = 'atl'\n",
    "        elif team_s == 'Baltimore Ravens':\n",
    "            ts = 'rav'\n",
    "        elif team_s == 'Buffalo Bills':\n",
    "            ts = 'buf'\n",
    "        elif team_s == 'Carolina Panthers':\n",
    "            ts = 'car'\n",
    "        elif team_s == 'Chicago Bears':\n",
    "            ts = 'chi'\n",
    "        elif team_s == 'Cincinnati Bengals':\n",
    "            ts = 'cin'\n",
    "        elif team_s == 'Cleveland Browns':\n",
    "            ts = 'cle'\n",
    "        elif team_s == 'Dallas Cowboys':\n",
    "            ts = 'dal'\n",
    "        elif team_s == 'Denver Broncos':\n",
    "            ts = 'den'\n",
    "        elif team_s == 'Detroit Lions':\n",
    "            ts = 'det'\n",
    "        elif team_s == 'Green Bay Packers':\n",
    "            ts = 'gnb'\n",
    "        elif team_s == 'Houston Texans':\n",
    "            ts = 'htx'\n",
    "        elif team_s == 'Indianapolis Colts':\n",
    "            ts = 'clt'\n",
    "        elif team_s == 'Jacksonville Jaguars':\n",
    "            ts = 'jax'\n",
    "        elif team_s == 'Kansas City Chiefs':\n",
    "            ts = 'kan'\n",
    "        elif team_s == 'Miami Dolphins':\n",
    "            ts = 'mia'\n",
    "        elif team_s == 'Minnesota Vikings':\n",
    "            ts = 'min'\n",
    "        elif team_s == 'New England Patriots':\n",
    "            ts = 'nwe'\n",
    "        elif team_s == 'New Orleans Saints':\n",
    "            ts = 'nor'\n",
    "        elif team_s == 'New York Giants':\n",
    "            ts = 'nyg'\n",
    "        elif team_s == 'New York Jets':\n",
    "            ts = 'nyj'\n",
    "        elif team_s == 'Oakland Raiders':\n",
    "            ts = 'rai'\n",
    "        elif team_s == 'Philadelphia Eagles':\n",
    "            ts = 'phi'\n",
    "        elif team_s == 'Pittsburgh Steelers':\n",
    "            ts = 'pit'\n",
    "        elif team_s == 'San Diego Chargers':\n",
    "            ts = 'sdg'\n",
    "        elif team_s == 'San Francisco 49ers':\n",
    "            ts = 'sfo'\n",
    "        elif team_s == 'Seattle Seahawks':\n",
    "            ts = 'sea'\n",
    "        elif team_s == 'St. Louis Rams':\n",
    "            ts = 'ram'\n",
    "        elif team_s == 'Tampa Bay Buccaneers':\n",
    "            ts = 'tam'\n",
    "        elif team_s == 'Tennessee Titans':\n",
    "            ts = 'oti'\n",
    "        elif team_s == 'Washington Redskins':\n",
    "            ts = 'was'\n",
    "    except NameError:\n",
    "        print('Invalid team name')\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['Week','Day','Date','Unnamed: 3_level_1','Unnamed: 4_level_1','Unnamed: 5_level_1','OT',\n",
    "            'Rec','Unnamed: 8_level_1','Opp','Tm','Opp','1stD','TotYd','PassY','RushY','TO','1stD',\n",
    "            'TotYd','PassY','RushY','TO','Offense','Defense','Sp. Tms','Name','Year']\n",
    "col_name2 = ['Week','Day','Date','Time','Boxscore','W/L','OT','Rec','Home/Away','Opp',\n",
    "             'Score_Home','Opp_Score','1stD','TotYd','PassY','RushY','TO','Opp_1stD','Opp_TotYd','Opp_PassY',\n",
    "             'Opp_RushY','Opp_TO','Offense','Defense','Sp. Tms','Name','Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urlSplit(inputlist):\n",
    "    ''' Used to slice the boxscore link to get and sort link and date\n",
    "    '''\n",
    "    urlList = []\n",
    "    for item in inputlist:\n",
    "        sort = item.split('/')[-1][:9]\n",
    "        urlList.append(sort)\n",
    "    return sorted(urlList, reverse=False)\n",
    "\n",
    "def boxscore(url):\n",
    "    '''returns the link to the boxscore and the date the game was played'''\n",
    "    html = get(url)\n",
    "    soup = Soup(html)\n",
    "    boxlinks = str(soup.find('a', {'href': 'boxscore'})).split('\"')                    # Finds all a tags with a href link and splits on \"\n",
    "    links_list = [x for x in boxlinks if x.startswith('/boxscore')][1:-3]              # creates a list of all the links that starts with /boxscore\n",
    "    links_list = ['https://www.pro-football-reference.com' + x for x in links_list]    # creates the complete url to the boxscore links\n",
    "    df = pd.DataFrame(links_list, columns =['Links'])                                  # creates a dataframe containing all of the url links just created\n",
    "    df['Date'] = urlSplit(links_list)                                                  # add a new column that uses urlSplit to get an idea of the date\n",
    "    return df['Links'], df['Date']\n",
    "\n",
    "def get_boxscore_stats(url):\n",
    "    '''reutns a dataframe that contains home and away boxscores\n",
    "    use the link from the boxscore link generated from the master\n",
    "    dataframe\n",
    "    '''\n",
    "    boxstats = pullTable(url,'team_stats')                                             # Pull box table from boxscore url\n",
    "    boxstats.columns = ['Stats', 'Home', 'Away']                                       # rename column names\n",
    "    homebox = boxstats[['Stats','Home']]                                               # create a list for home and away teams\n",
    "    awaybox = boxstats[['Stats','Away']]\n",
    "    homebox = homebox.transpose()                                                      # Transpose the tables\n",
    "    awaybox = awaybox.transpose()\n",
    "    home_colnames = ['Home_' + x for x in homebox.iloc[0]]                             # add Home or Away to column names\n",
    "    away_colnames = ['Away_' + x for x in awaybox.iloc[0]]\n",
    "    zip_Homeboxscore = list(zip(home_colnames, homebox.iloc[1]))                       # zip list of columns and data together\n",
    "    zip_Awayboxscore = list(zip(away_colnames, awaybox.iloc[1]))\n",
    "    boxscorelist = zip_Homeboxscore + zip_Awayboxscore                                 # combine lists together\n",
    "    box_col = [col[0].replace(' ','_').replace('.','') for col in boxscorelist]        # Replace spaces with _ and remove .\n",
    "    box_stats = pd.Series([col[1] for col in boxscorelist], index=box_col)             \n",
    "    boxdf= pd.DataFrame(columns=box_col)\n",
    "    boxdf = boxdf.append(box_stats, ignore_index=True)\n",
    "    boxdf['BoxScoreURL'] = url\n",
    "    return boxdf\n",
    "\n",
    "\n",
    "def getGameInfo(url):\n",
    "    '''Gets table from Game Info table that is within a HTML comment\n",
    "    Will return a list of lists were [n][0] = column name and [n][1] is the infomation\n",
    "    [('Won_Toss', 'Cardinals (deferred)'),\n",
    "     ('Roof', 'retractable roof (closed)'),\n",
    "     ('Surface', 'grass'),\n",
    "     ('Duration', '2:56'),\n",
    "     ('Attendance', ' 60,104 '),\n",
    "     ('Vegas Line', 'Arizona Cardinals -2.5'),\n",
    "     ('Over/Under', '46.0(over) '),\n",
    "     ('Weather', '999  F'),\n",
    "     ('relative humidity', '222%'),...\n",
    "    '''\n",
    "    html = get(url)\n",
    "    soup = BS(html, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text: isinstance(text, Comment))                        # retrieve all the comments from the HTML\n",
    "    game_comments = []\n",
    "    \n",
    "    for line in comments:\n",
    "        if '<div class=\"table_outer_container\">' in line:                                          # loop throught the table i want\n",
    "            game_comments.append(re.sub('<[^>]+>', ' ', line))                                     # use regex to replace everything between the <> tags and append to game comments\n",
    "            if '</table>' in line:                                                                 # break out of the for loop once it hits the ending table tag \n",
    "                break\n",
    "    game_info = [x.split('\\n') for x in game_comments]                                             # split on newlines to create a clean list\n",
    "    game_info = game_info[0][4:12]                                                                 # more cleaning, i only want these 8 items\n",
    "    game_info = [x.replace('Won Toss','Won_Toss') if 'Won Toss' in x else x for x in game_info]    # replace the space in the Won Toss item, cleaning/prep\n",
    "    \n",
    "    game_loop = []                                                                                 # creating a game and weather list to help create the ending list bc some games are played in a dome and dont have the weather items\n",
    "    weather_break_list = []\n",
    "    for count, row in enumerate(game_info):\n",
    "        if count == 5 and 'Weather' in row:                                                        # if this page has weather info it will split it and then add it to the weather_break_list\n",
    "            weather_break = row.split(',')\n",
    "            weather_break_list.append(row)\n",
    "        else:                                                                                      # appends everything that is larger then 1 in len to game_loop\n",
    "            if len(row) > 1:\n",
    "                game_loop.append(row)\n",
    "   \n",
    "    if len(weather_break_list) > 1:                                                                # creates dummy info if weather_break_list is empty\n",
    "        weather_break_list = [x.split(',') for x in weather_break_list][0]\n",
    "    missing_weather = ['Weather  999 degrees','relative humidity  222%','wind  222 mph']\n",
    "    \n",
    "    if len(weather_break_list) == 0:                                                               #append weather_break_list to game_loop and fix some formatting issues\n",
    "        game_loop.extend(missing_weather)\n",
    "    else:\n",
    "        for x in weather_break_list:\n",
    "            x = x.split(',')\n",
    "            for i in x:\n",
    "                i = i.replace('relative humidity ',' relative_humidity  ').replace(' wind ', '  wind  ')\n",
    "                game_loop.append(i)\n",
    "    #breaking list on double spaces and create a place to split using |\n",
    "    game_detail = []\n",
    "    for x in game_loop:\n",
    "        game_detail.append(x.replace('  ','|'))\n",
    "\n",
    "    # split on | and setting max split to 2 and then removing the empty list items \n",
    "    details = [x.split('|',2) for x in game_detail]\n",
    "    for x in details:\n",
    "        while(\"\" in x):\n",
    "            x.remove(\"\")\n",
    "    #creating game titles(headers) and game_data(info) and doing a little more formatting/cleaning\n",
    "    #returning a zipped list of the header and info\n",
    "    game_titles = [x[0] for x in details]\n",
    "    game_data = [x[1].replace('|','').replace('degrees',' F') for x in details]\n",
    "    game_data\n",
    "    return list(zip(game_titles, game_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDF = pd.DataFrame()\n",
    "team_list = ['crd', 'atl', 'rav', 'buf', 'car', 'chi', 'cin', 'cle', 'dal', 'den', 'det','gnb', \n",
    "'htx', 'clt', 'jax', 'kan', 'mia', 'min', 'nwe', 'nor', 'nyg', 'nyj', 'rai', 'phi', 'pit', \n",
    "'sdg', 'sfo', 'sea', 'ram', 'tam', 'oti', 'was']\n",
    "years = [x for x in range(2019,2020)]\n",
    "for year in years:\n",
    "    nflDF = pd.DataFrame()\n",
    "    for team in team_list:\n",
    "        base = 'https://www.pro-football-reference.com'\n",
    "        url = base + '/teams/' + team + '/' + str(year) + '.htm'\n",
    "        html = get(url)\n",
    "        soup = Soup(html)\n",
    "        df = pd.read_html(str(soup.find('table')[1]))[0]\n",
    "        df = df[df['Unnamed: 9_level_0','Opp'] != 'Bye Week']\n",
    "        df = df[df['Unnamed: 9_level_0','Opp'] != 'Playoffs']\n",
    "#         df['Boxscorelink','Link'] = base + '/' + str(boxscore(url))\n",
    "        df['Team','Name'] = rename_Abv2Full(team)\n",
    "        df['Team','Year'] = year\n",
    "        df['BoxScore','Link'] = boxscore(url)[0]\n",
    "        df['Boxscore','BDate'] = boxscore(url)[1]\n",
    "#         df.dropna(subset=['BoxScore','Link'])\n",
    "        nflDF = nflDF.append(df, ignore_index=True)\n",
    "    masterDF = masterDF.append(nflDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# masterDF['BoxScore'.'Link'].head(n=22)\n",
    "test_urls = masterDF['BoxScore','Link'].head(n=50)\n",
    "test_urls = test_urls.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = pd.DataFrame()\n",
    "for url in test_urls:\n",
    "    test_list.append(get_boxscore_stats(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(str(soup.find('table')[1]))[0]\n",
    "df['Team','Name'] = 'Dallas Cowboys'\n",
    "df['Team','Year'] = 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [df.columns[x][1] for x in range(27)]\n",
    "df.columns = [col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('filename') as f:\n",
    "    for x in range (number of fields):\n",
    "        zip(list(nlfstatsdict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nflstatsdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(nflstatsdict, orient='index')\n",
    "pd.DataFrame.from_dict({(i,j): user_dict[i][j] \n",
    "                           for i in user_dict.keys() \n",
    "                           for j in user_dict[i].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing pulling boxscore url link\n",
    "team_list = ['rai']\n",
    "year = str(2019)\n",
    "max_week = 17\n",
    "base = 'https://www.pro-football-reference.com'\n",
    "url = base + '/teams/' + team + '/' + year + '.htm'\n",
    "result = requests.get('https://www.pro-football-reference.com/teams/' + team + '/' + year + '.htm')\n",
    "soup = bs4.BeautifulSoup(result.text)\n",
    "def boxscore(url):\n",
    "    table_gamelog = soup.find('div', id = 'div_games')\n",
    "    for count1, row in enumerate(table_gamelog.find_all('tr')):\n",
    "        for count, x in enumerate(row.find_all('td')):\n",
    "            for a in x.find_all('a', href=True):\n",
    "                a = a['href']\n",
    "                if a.startswith('/boxscores'):\n",
    "                    boxscore = a\n",
    "    box_url = base + boxscore\n",
    "    boxstats = pullTable(box_url,'team_stats')\n",
    "    return boxstats\n",
    "\n",
    "boxscore = boxscore(result) \n",
    "boxscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, key in enumerate(ordered_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for count, row in enumerate(table_gamelog.find_all('tr')):\n",
    "#         row_data = row.find_all('td')\n",
    "#         print(len(row_data), row_data)\n",
    "        if(count - 1) <= max_week and row.text.split('\\n')[1].isdigit() and row.text.split('\\n')[ordered_key.index('Opp') + 1] != 'Bye Week':\n",
    "            for count, col in enumerate(row.find_all('td')):\n",
    "                if count == 0:\n",
    "                    if col.text == '':\n",
    "                        dict1[ordered_keys[count]].append(0)\n",
    "                        week = int(col.text)\n",
    "                    else:\n",
    "                        week = int(col.text)\n",
    "                        dict1[ordered_keys[count]].append(int(col.text))\n",
    "                elif count in [4,6]:\n",
    "                    dict1[ordered_key[count]].append(col.text)\n",
    "                elif count == 8:\n",
    "                    opp = col.text\n",
    "                    dict1[ordered_keys[count]].append(col.text)\n",
    "                elif count == 2:\n",
    "                    if 'January' in col.text or 'February' in col.text:\n",
    "                        date_str = get_date(str(int(year)+ 1), col.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findTables(\"https://www.pro-football-reference.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFC = pullTable(\"https://www.pro-football-reference.com/\",'AFC')\n",
    "NFC = pullTable(\"https://www.pro-football-reference.com/\",'NFC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFC = AFC[~AFC.Tm.str.startswith(' AF')]\n",
    "NFC = NFC[~NFC.Tm.str.startswith(' NF')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFC['Tm'] = AFC['Tm'].str.replace('*', '', regex=True).str.replace('+', '', regex=True)\n",
    "NFC['Tm'] = NFC['Tm'].str.replace('*', '', regex=True).str.replace('+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.pro-football-reference.com/'     \n",
    "html = requests.get(url).text                                 \n",
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
